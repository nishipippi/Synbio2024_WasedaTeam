# Synbio2024 Waseda Team - Mutant Activity Evaluation Pipeline

**Last Updated:** 2025-05-29 (nishipippi)

## Project Overview

This project, developed by Team Waseda for Synbio2024, implements a computational pipeline to identify promising protein variants with enhanced activity. The workflow involves several steps:
1.  Filtering and selecting effective single/double point mutations from an initial dataset.
2.  Generating combinations of these mutations (up to three) and scoring them.
3.  Converting these mutation combinations into full amino acid sequences.
4.  Predicting the activity of these novel sequences using a k-Nearest Neighbors (k-NN) regression model trained on existing data.

The primary goal is to systematically explore the mutation landscape and predict new protein sequences with potentially higher activity than the wild type.

## Core Pipeline Scripts

The main workflow consists of the following four Python scripts, executed in sequence:

### 1. `dupdelete_ver2.py`

* **Description:** This script processes an initial dataset of point mutations (e.g., A129D). It identifies and removes redundant or less effective mutations at the same amino acid position. For instance, if both A129D and A129G mutations exist, and A129G results in higher activity, A129D will be removed. The script focuses on retaining only the most potent single or double mutations that show improved activity over the wild type.
* **Input:** `hopeful_point_mutation.xlsx`
    * Must contain columns like `mutation` (e.g., "A129D" or "A129D:B30E") and `gain` (activity score).
* **Output:** `pointmutation_dupdel.xlsx`
    * A filtered list of unique and effective point mutations.

### 2. `mutationcombo_ver2.py`

* **Description:** Takes the filtered list of effective point mutations from `pointmutation_dupdel.xlsx` and generates combinations of these mutations (up to a maximum of three distinct mutations per combination). It calculates a "score" for each combination by summing the adjusted "gain" values (gain relative to wild-type activity: 3.719212132) of the individual mutations involved. The script then outputs the top 100 combinations with the highest scores.
* **Input:** `pointmutation_dupdel.xlsx` (output from `dupdelete_ver2.py`)
* **Output:** `hopeful_mutant.csv`
    * A CSV file containing the top 100 mutation combinations (`mutationcombo` column) and their calculated `score`.

### 3. `synbio_re.py`

* **Description:** This script converts the mutation combinations (e.g., "A129D:G56S") from `hopeful_mutant.csv` into full amino acid sequences. It applies these mutations to a provided wild-type sequence.
* **Input:** `hopeful_mutant.csv` (output from `mutationcombo_ver2.py`)
    * Assumes a `mutationcombo` column with mutation strings.
    * Uses a default wild-type sequence if an `original` column is not present: "MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK"
* **Output:** `mutant_output.csv`
    * A CSV file with the original mutation combinations, the wild-type sequence, and the `created sequence` (full mutated amino acid sequence).

### 4. `knn_nishi_with_GPU.py`

* **Description:** This script predicts the activity of the novel mutant sequences generated by `synbio_re.py`. It uses a k-Nearest Neighbors (k-NN) regression model.
    1.  Training Data: Sequences and their activities from `gfp_data.csv` (specifically, 'created sequence' and 'gain' columns) are cleaned (removing '-' and '.'), padded to a uniform length, and then one-hot encoded.
    2.  Prediction Data: Sequences from `mutant_output.csv` (output of `synbio_re.py`) are similarly processed (cleaned, padded, one-hot encoded).
    3.  Model Training: The k-NN model (KNeighborsRegressor from scikit-learn) is trained on the encoded `gfp_data.csv` data.
    4.  Prediction: The trained model predicts the activity for the encoded sequences from `mutant_output.csv`.
    The script attempts to use a GPU if available (via TensorFlow, though scikit-learn's KNN doesn't natively run on GPU without specific libraries like cuML).
* **Inputs:**
    * `gfp_data.csv`: Dataset for training the k-NN model. Expected to have `created sequence` (amino acid sequences) and `gain` (activity values) columns.
    * `mutant_output.csv`: (Output from `synbio_re.py`) Dataset of mutant sequences for which to predict activity. Expected to have a `created sequence` column.
* **Output:** `predicted_mutant_activities.csv`
    * A CSV file containing the `created sequence` from `mutant_output.csv` and their `predicted_activity`.

## Workflow Summary

1.  **Start with an initial dataset of mutations:** `hopeful_point_mutation.xlsx`
2.  Run `python dupdelete_ver2.py`
    * Input: `hopeful_point_mutation.xlsx`
    * Output: `pointmutation_dupdel.xlsx`
3.  Run `python mutationcombo_ver2.py`
    * Input: `pointmutation_dupdel.xlsx`
    * Output: `hopeful_mutant.csv`
4.  Run `python synbio_re.py`
    * Input: `hopeful_mutant.csv`
    * Output: `mutant_output.csv`
5.  Run `python knn_nishi_with_GPU.py`
    * Inputs: `mutant_output.csv`, `gfp_data.csv`
    * Output: `predicted_mutant_activities.csv` (final predictions)

## Additional Provided Scripts

The following scripts were also provided and might be used for related analyses or alternative approaches:

### `hamming_dist_protain2protain.py`

* **Description:** Calculates the Hamming distance between a specific reference protein sequence and a list of other sequences from a CSV file (`gfp_data.csv`). It filters and saves pairs of sequences that have a Hamming distance of 1 or 2. Sequences are cleaned and padded before distance calculation.
* **Input:** `gfp_data.csv`
    * Must contain `sequence`, `activity`, and `kind` columns. Filters for `kind == 'avGFP'`.
* **Outputs:**
    * `hamming_distance_1_combinations.csv`
    * `hamming_distance_2_combinations.csv`

### `regression.py`

* **Description:** Trains a neural network (Multi-Layer Perceptron) for regression to predict protein activity based on sequence.
    1.  Input: Sequences and activities from `gfp_data.csv`.
    2.  Processing: Sequences are cleaned, padded, and one-hot encoded.
    3.  Model: A TensorFlow/Keras Sequential model with Dense layers.
    4.  Training: Trained on a split of the input data.
    5.  Output: Predicts activities on the test set and saves the top 100 sequences with the highest predicted activities.
* **Input:** `gfp_data.csv`
    * Must contain `sequence` and `activity` columns.
* **Output:** `predicted_high_activity_sequences.csv`

## Prerequisites

* Python 3.x
* The following Python libraries:
    * pandas
    * numpy
    * scikit-learn
    * tensorflow (primarily for `knn_nishi_with_GPU.py` to check GPU availability and for `regression.py`)
    * tqdm (for progress bars in `hamming_dist_protain2protain.py`)

## Installation

Install the required libraries using pip:
```bash
pip install pandas numpy scikit-learn tensorflow tqdm
```

## How to Run

1.  Ensure all required Python scripts (`dupdelete_ver2.py`, `mutationcombo_ver2.py`, `synbio_re.py`, `knn_nishi_with_GPU.py`) are in the same directory.
2.  Place the initial input files in the same directory:
    * `hopeful_point_mutation.xlsx` (for `dupdelete_ver2.py`)
    * `gfp_data.csv` (for `knn_nishi_with_GPU.py`, and also used by `hamming_dist_protain2protain.py` and `regression.py` if run)
3.  Execute the scripts in the order specified in the "Workflow Summary" section:
    ```bash
    python dupdelete_ver2.py
    python mutationcombo_ver2.py
    python synbio_re.py
    python knn_nishi_with_GPU.py
    ```
4.  The final output with predicted activities for newly designed mutants will be in `predicted_mutant_activities.csv`.
